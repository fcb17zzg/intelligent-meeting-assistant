#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆMeetingTranscriberæµ‹è¯• - å¢å¼ºç‰ˆ
æ·»åŠ é•¿éŸ³é¢‘å¤„ç†å’ŒAPIæµ‹è¯•
"""
import sys
import os
import tempfile
import numpy as np
import soundfile as sf
import pytest
import time
import json
import logging
from typing import Dict, Any, List

# æ·»åŠ è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
src_dir = os.path.join(project_root, 'src')
sys.path.insert(0, src_dir)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

print("="*60)
print("å¢å¼ºç‰ˆMeetingTranscriberæµ‹è¯•")
print("="*60)


class TestMeetingTranscriberEnhanced:
    """å¢å¼ºç‰ˆæµ‹è¯• - åŒ…å«é•¿éŸ³é¢‘å¤„ç†å’ŒAPIæµ‹è¯•"""
    
    @pytest.fixture
    def test_audio_file(self):
        """åˆ›å»ºçŸ­æµ‹è¯•éŸ³é¢‘ï¼ˆ3ç§’ï¼‰"""
        import uuid
        temp_dir = tempfile.gettempdir()
        filename = os.path.join(temp_dir, f"test_audio_{uuid.uuid4().hex}.wav")
        
        # ç”Ÿæˆç®€å•éŸ³é¢‘
        duration = 3.0  # 3ç§’ï¼ŒçŸ­ä¸€ç‚¹åŠ å¿«æµ‹è¯•
        sample_rate = 16000
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        audio_data = 0.5 * np.sin(2 * np.pi * 1000 * t)  # 1kHzæ­£å¼¦æ³¢
        
        sf.write(filename, audio_data, sample_rate)
        
        yield filename
        
        # æ¸…ç†
        try:
            if os.path.exists(filename):
                os.unlink(filename)
        except:
            pass
    
    @pytest.fixture
    def medium_audio_file(self):
        """åˆ›å»ºä¸­ç­‰æµ‹è¯•éŸ³é¢‘ï¼ˆ1åˆ†é’Ÿï¼‰"""
        import uuid
        temp_dir = tempfile.gettempdir()
        filename = os.path.join(temp_dir, f"medium_audio_{uuid.uuid4().hex}.wav")
        
        # ç”Ÿæˆ1åˆ†é’ŸéŸ³é¢‘
        duration = 60.0  # 1åˆ†é’Ÿ
        sample_rate = 16000
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        
        # ç”Ÿæˆå¤šé¢‘ç‡éŸ³é¢‘ï¼Œæ¨¡æ‹Ÿè¯­éŸ³
        audio_data = 0.3 * np.sin(2 * np.pi * 100 * t)  # ä½é¢‘
        audio_data += 0.2 * np.sin(2 * np.pi * 300 * t)  # ä¸­é¢‘
        audio_data += 0.1 * np.sin(2 * np.pi * 500 * t)  # é«˜é¢‘
        
        # æ·»åŠ é™éŸ³æ®µ
        for i in range(0, int(duration), 10):  # æ¯10ç§’
            start = i * sample_rate
            end = start + 2 * sample_rate  # 2ç§’é™éŸ³
            if end < len(audio_data):
                audio_data[start:end] *= 0.01  # å¤§å¹…é™ä½éŸ³é‡
        
        sf.write(filename, audio_data, sample_rate)
        
        yield filename
        
        # æ¸…ç†
        try:
            if os.path.exists(filename):
                os.unlink(filename)
        except:
            pass
    
    @pytest.fixture
    def long_audio_file(self):
        """åˆ›å»ºé•¿æµ‹è¯•éŸ³é¢‘ï¼ˆ5åˆ†é’Ÿï¼‰- ç”¨äºé•¿éŸ³é¢‘å¤„ç†æµ‹è¯•"""
        import uuid
        temp_dir = tempfile.gettempdir()
        filename = os.path.join(temp_dir, f"long_audio_{uuid.uuid4().hex}.wav")
        
        # ç”Ÿæˆ5åˆ†é’ŸéŸ³é¢‘
        duration = 300.0  # 5åˆ†é’Ÿ
        sample_rate = 16000
        
        # ä¸ºäº†æµ‹è¯•é€Ÿåº¦ï¼Œç”Ÿæˆç®€åŒ–çš„éŸ³é¢‘
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        
        # äº¤æ›¿ç”Ÿæˆä¸åŒé¢‘ç‡çš„éŸ³é¢‘ï¼Œæ¨¡æ‹Ÿä¸åŒè¯´è¯äºº
        audio_data = np.zeros_like(t)
        
        # ç¬¬ä¸€ä¸ªè¯´è¯äººæ¨¡å¼ï¼ˆ0-2åˆ†é’Ÿï¼‰
        mask1 = t < 120  # å‰2åˆ†é’Ÿ
        audio_data[mask1] = 0.25 * np.sin(2 * np.pi * 150 * t[mask1])
        
        # ç¬¬äºŒä¸ªè¯´è¯äººæ¨¡å¼ï¼ˆ2-3åˆ†é’Ÿï¼‰
        mask2 = (t >= 120) & (t < 180)  # 2-3åˆ†é’Ÿ
        audio_data[mask2] = 0.2 * np.sin(2 * np.pi * 250 * t[mask2])
        
        # ç¬¬ä¸€ä¸ªè¯´è¯äººæ¨¡å¼ï¼ˆ3-5åˆ†é’Ÿï¼‰
        mask3 = t >= 180  # 3-5åˆ†é’Ÿ
        audio_data[mask3] = 0.25 * np.sin(2 * np.pi * 150 * t[mask3])
        
        # æ·»åŠ å°‘é‡å™ªå£°
        audio_data += 0.01 * np.random.randn(len(t))
        
        sf.write(filename, audio_data, sample_rate)
        
        yield filename
        
        # æ¸…ç†
        try:
            if os.path.exists(filename):
                os.unlink(filename)
        except:
            pass
    
    @pytest.fixture
    def progress_callback_data(self):
        """è¿›åº¦å›è°ƒæ•°æ®æ”¶é›†å™¨"""
        data = []
        
        def callback(progress):
            data.append({
                'percentage': progress.percentage,
                'status': progress.current_status,
                'chunk': progress.current_chunk,
                'total_chunks': progress.total_chunks,
                'timestamp': time.time()
            })
            logger.info(f"è¿›åº¦: {progress.percentage:.1f}% - {progress.current_status}")
        
        return {'data': data, 'callback': callback}
    
    def test_01_basic_workflow(self, test_audio_file):
        """æµ‹è¯•1: åŸºæœ¬å·¥ä½œæµç¨‹"""
        print("\n" + "="*60)
        print("æµ‹è¯•1: åŸºæœ¬å·¥ä½œæµç¨‹")
        print("="*60)
        
        from audio_processing.core.meeting_transcriber import MeetingTranscriber
        from audio_processing.models.transcription_result import TranscriptionResult
        
        # åˆ›å»ºè½¬å½•å™¨
        transcriber = MeetingTranscriber(
            whisper_model_size="base",
            language="zh",
            device="cpu",
        )
        
        print(f"âœ… è½¬å½•å™¨åˆ›å»ºæˆåŠŸ")
        print(f"  æµ‹è¯•éŸ³é¢‘: {test_audio_file}")
        print(f"  éŸ³é¢‘æ—¶é•¿: 3ç§’")
        
        # æ‰§è¡Œè½¬å½•
        result = transcriber.transcribe_with_speakers(
            test_audio_file,
            num_speakers=2
        )
        
        # éªŒè¯ç»“æœ
        assert isinstance(result, TranscriptionResult)
        print(f"âœ… è½¬å½•å®Œæˆ")
        print(f"  å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’")
        print(f"  åˆ†æ®µæ•°: {len(result.segments)}")
        print(f"  è¯´è¯äººæ•°: {result.metadata.get('num_speakers_detected', 0)}")
        
        # åŸºæœ¬éªŒè¯
        assert len(result.segments) > 0
        assert result.audio_duration > 0
        assert result.processing_time > 0
        
        return True
    
    def test_02_whisper_integration(self):
        """æµ‹è¯•2: Whisperé›†æˆ"""
        print("\n" + "="*60)
        print("æµ‹è¯•2: Whisperé›†æˆ")
        print("="*60)
        
        from audio_processing.core.whisper_client import WhisperClient, WhisperConfig
        
        # åˆ›å»ºWhisperå®¢æˆ·ç«¯
        config = WhisperConfig(
            model_size="base",
            device="cpu",
            language="zh"
        )
        client = WhisperClient(config)
        
        # åˆå§‹åŒ–
        assert client.initialize() is True
        print(f"âœ… WhisperClientåˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ•°æ®
        duration = 2.0
        sample_rate = 16000
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        test_audio = 0.5 * np.sin(2 * np.pi * 1000 * t)
        
        # æµ‹è¯•è½¬å½•
        try:
            result = client.transcribe(test_audio, language="zh")
            print(f"âœ… Whisperè½¬å½•æˆåŠŸ")
            print(f"  æ–‡æœ¬é•¿åº¦: {len(result.text)}")
            if result.text:
                print(f"  æ–‡æœ¬é¢„è§ˆ: {result.text[:50]}...")
            return True
        except Exception as e:
            print(f"âš ï¸  Whisperè½¬å½•å¤±è´¥ï¼ˆå¯èƒ½æ­£å¸¸ï¼‰: {e}")
            return True  # ä»ç„¶é€šè¿‡ï¼Œå› ä¸ºå®¢æˆ·ç«¯æœ¬èº«æ˜¯å¯ç”¨çš„
    
    def test_03_audio_processor(self, test_audio_file):
        """æµ‹è¯•3: éŸ³é¢‘å¤„ç†å™¨"""
        print("\n" + "="*60)
        print("æµ‹è¯•3: éŸ³é¢‘å¤„ç†å™¨")
        print("="*60)
        
        from audio_processing.core.audio_processor import AudioProcessor
        
        processor = AudioProcessor()
        
        # æµ‹è¯•éŸ³é¢‘ä¿¡æ¯è·å–
        info = processor.get_audio_info(test_audio_file)
        print(f"âœ… éŸ³é¢‘ä¿¡æ¯è·å–æˆåŠŸ")
        print(f"  æ—¶é•¿: {info.get('duration', 0):.2f}ç§’")
        print(f"  é‡‡æ ·ç‡: {info.get('sample_rate', 0)}")
        print(f"  é€šé“æ•°: {info.get('channels', 1)}")
        
        # æµ‹è¯•é¢„å¤„ç†
        try:
            processed = processor.preprocess_audio(test_audio_file)
            print(f"âœ… éŸ³é¢‘é¢„å¤„ç†æˆåŠŸ")
            print(f"  è¾“å‡ºæ–‡ä»¶: {processed}")
            assert os.path.exists(processed)
            
            # æ¸…ç†
            if os.path.exists(processed):
                os.unlink(processed)
                
        except Exception as e:
            print(f"âš ï¸  éŸ³é¢‘é¢„å¤„ç†å¤±è´¥: {e}")
        
        return True
    
    def test_04_save_results(self, test_audio_file):
        """æµ‹è¯•4: ç»“æœä¿å­˜"""
        print("\n" + "="*60)
        print("æµ‹è¯•4: ç»“æœä¿å­˜")
        print("="*60)
        
        from audio_processing.core.meeting_transcriber import MeetingTranscriber
        from audio_processing.models.transcription_result import TranscriptionResult, SpeakerSegment
        
        transcriber = MeetingTranscriber(device="cpu")
        
        # åˆ›å»ºè™šæ‹Ÿç»“æœè¿›è¡Œæµ‹è¯•
        virtual_result = TranscriptionResult(
            segments=[
                SpeakerSegment(
                    speaker="SPEAKER_00",
                    start_time=0.0,
                    end_time=10.0,
                    text="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯ä¿å­˜åŠŸèƒ½ã€‚",
                    confidence=0.9,
                    language="zh"
                ),
                SpeakerSegment(
                    speaker="SPEAKER_01",
                    start_time=10.0,
                    end_time=15.0,
                    text="ç¬¬äºŒä¸ªè¯´è¯äººçš„å‘è¨€å†…å®¹ã€‚",
                    confidence=0.8,
                    language="zh"
                )
            ],
            metadata={
                "test": "virtual",
                "num_speakers_detected": 2,
                "processing_time": 5.0
            },
            processing_time=1.0,
            audio_duration=15.0,
            language="zh"
        )
        
        # æµ‹è¯•ä¿å­˜ä¸ºJSON
        json_file = "test_output.json"
        if os.path.exists(json_file):
            os.unlink(json_file)
        
        saved_path = transcriber.save_result(virtual_result, json_file, "json")
        assert os.path.exists(json_file)
        print(f"âœ… JSONä¿å­˜æˆåŠŸ: {saved_path}")
        
        # éªŒè¯JSONå†…å®¹
        with open(json_file, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
            assert 'segments' in json_data
            assert len(json_data['segments']) == 2
            assert json_data['metadata']['num_speakers_detected'] == 2
        
        # æµ‹è¯•ä¿å­˜ä¸ºæ–‡æœ¬
        txt_file = "test_output.txt"
        if os.path.exists(txt_file):
            os.unlink(txt_file)
        
        saved_path = transcriber.save_result(virtual_result, txt_file, "txt")
        assert os.path.exists(txt_file)
        print(f"âœ… æ–‡æœ¬ä¿å­˜æˆåŠŸ: {saved_path}")
        
        # éªŒè¯æ–‡æœ¬å†…å®¹
        with open(txt_file, 'r', encoding='utf-8') as f:
            content = f.read()
            assert "SPEAKER_00" in content
            assert "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬" in content
        
        # æ¸…ç†
        for file in [json_file, txt_file]:
            if os.path.exists(file):
                os.unlink(file)
        
        return True
    
    def test_05_speaker_summary(self):
        """æµ‹è¯•5: è¯´è¯äººæ‘˜è¦"""
        print("\n" + "="*60)
        print("æµ‹è¯•5: è¯´è¯äººæ‘˜è¦")
        print("="*60)
        
        from audio_processing.core.meeting_transcriber import MeetingTranscriber
        from audio_processing.models.transcription_result import TranscriptionResult, SpeakerSegment
        
        transcriber = MeetingTranscriber(device="cpu")
        
        # åˆ›å»ºæµ‹è¯•ç»“æœ
        test_result = TranscriptionResult(
            segments=[
                SpeakerSegment(
                    speaker="SPEAKER_00",
                    start_time=0.0,
                    end_time=10.0,
                    text="ç¬¬ä¸€ä¸ªè¯´è¯äººçš„ç¬¬ä¸€æ¬¡å‘è¨€",
                    confidence=0.9,
                    language="zh"
                ),
                SpeakerSegment(
                    speaker="SPEAKER_01",
                    start_time=10.0,
                    end_time=20.0,
                    text="ç¬¬äºŒä¸ªè¯´è¯äººçš„å‘è¨€",
                    confidence=0.8,
                    language="zh"
                ),
                SpeakerSegment(
                    speaker="SPEAKER_00",
                    start_time=20.0,
                    end_time=30.0,
                    text="ç¬¬ä¸€ä¸ªè¯´è¯äººçš„ç¬¬äºŒæ¬¡å‘è¨€",
                    confidence=0.85,
                    language="zh"
                ),
                SpeakerSegment(
                    speaker="SPEAKER_02",
                    start_time=30.0,
                    end_time=35.0,
                    text="ç¬¬ä¸‰ä¸ªè¯´è¯äººçš„ç®€çŸ­å‘è¨€",
                    confidence=0.7,
                    language="zh"
                )
            ],
            metadata={"test": True},
            processing_time=5.0,
            audio_duration=35.0,
            language="zh"
        )
        
        # è·å–è¯´è¯äººæ‘˜è¦
        summary = transcriber.get_speaker_summary(test_result)
        
        print(f"âœ… è¯´è¯äººæ‘˜è¦ç”ŸæˆæˆåŠŸ")
        print(f"  æ£€æµ‹åˆ° {len(summary)} ä¸ªè¯´è¯äºº")
        
        # éªŒè¯æ‘˜è¦
        assert "SPEAKER_00" in summary
        assert "SPEAKER_01" in summary
        assert "SPEAKER_02" in summary
        
        # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
        speaker00 = summary["SPEAKER_00"]
        assert speaker00["total_segments"] == 2
        assert abs(speaker00["total_duration"] - 20.0) < 0.1
        assert speaker00["total_text_length"] > 0
        
        print(f"  SPEAKER_00: {speaker00['total_segments']}ä¸ªåˆ†æ®µ, "
              f"{speaker00['total_duration']:.1f}ç§’, "
              f"{speaker00['total_text_length']}å­—ç¬¦")
        
        return True
    
    def test_06_long_audio_processing(self, long_audio_file, progress_info=None):
        """æµ‹è¯•6: é•¿éŸ³é¢‘å¤„ç†ï¼ˆ5åˆ†é’ŸéŸ³é¢‘ï¼‰
        
        Args:
            long_audio_file: é•¿éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            progress_info: è¿›åº¦å›è°ƒä¿¡æ¯ï¼ŒåŒ…å« {'data': list, 'callback': function}
        """
        print("\n" + "="*60)
        print("æµ‹è¯•6: é•¿éŸ³é¢‘å¤„ç†ï¼ˆ5åˆ†é’ŸéŸ³é¢‘ï¼‰")
        print("="*60)
        
        from audio_processing.core.meeting_transcriber import MeetingTranscriber
        
        # åˆ›å»ºè½¬å½•å™¨
        transcriber = MeetingTranscriber(
            whisper_model_size="base",
            language="zh",
            device="cpu"
        )
        
        print(f"âœ… è½¬å½•å™¨åˆ›å»ºæˆåŠŸ")
        print(f"  æµ‹è¯•éŸ³é¢‘: {long_audio_file}")
        print(f"  é¢„è®¡æ—¶é•¿: 5åˆ†é’Ÿ")
        
        start_time = time.time()
        
        try:
            # å¦‚æœæ²¡æœ‰ä¼ å…¥progress_infoï¼Œåˆ›å»ºä¸€ä¸ª
            if progress_info is None:
                progress_data = []
                
                def progress_callback(progress):
                    progress_data.append({
                        'percentage': progress.percentage,
                        'status': progress.current_status,
                        'chunk': progress.current_chunk,
                        'total_chunks': progress.total_chunks,
                        'timestamp': time.time()
                    })
                    logger.info(f"è¿›åº¦: {progress.percentage:.1f}% - {progress.current_status}")
                
                progress_info = {'data': progress_data, 'callback': progress_callback}
            
            # ä½¿ç”¨é•¿éŸ³é¢‘å¤„ç†æ–¹æ³•
            result = transcriber.transcribe_long_audio(
                long_audio_file,
                chunk_duration=120,  # 2åˆ†é’Ÿåˆ†å—
                overlap_duration=3,  # 3ç§’é‡å 
                language="zh",
                num_speakers=2,
                progress_callback=progress_info['callback']
            )
            
            processing_time = time.time() - start_time
            
            print(f"âœ… é•¿éŸ³é¢‘å¤„ç†å®Œæˆ")
            print(f"  å®é™…å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’")
            print(f"  éŸ³é¢‘æ—¶é•¿: {result.audio_duration:.1f}ç§’")
            print(f"  åŠ é€Ÿæ¯”: {result.audio_duration/processing_time:.2f}x")
            print(f"  æ€»åˆ†æ®µæ•°: {len(result.segments)}")
            print(f"  è¯´è¯äººæ•°: {result.metadata.get('num_speakers_detected', 0)}")
            
            # æ£€æŸ¥é•¿éŸ³é¢‘å¤„ç†ç‰¹æœ‰çš„å…ƒæ•°æ®
            assert result.metadata.get('processing_mode') == 'long_audio'
            assert result.metadata.get('speaker_consistency_applied', False)
            
            # æ£€æŸ¥åˆ†å—é…ç½®
            chunk_config = result.metadata.get('chunk_config', {})
            assert 'total_chunks' in chunk_config
            print(f"  åˆ†å—æ•°: {chunk_config.get('total_chunks', 0)}")
            
            # æ£€æŸ¥è¿›åº¦å›è°ƒ
            progress_data = progress_info['data']
            assert len(progress_data) > 0
            print(f"  è¿›åº¦å›è°ƒæ¬¡æ•°: {len(progress_data)}")
            
            # éªŒè¯è¿›åº¦æ•°æ®
            for i, progress in enumerate(progress_data[-3:]):  # æ˜¾ç¤ºæœ€å3ä¸ªè¿›åº¦
                print(f"    è¿›åº¦{i+1}: {progress['percentage']:.1f}% - {progress['status']}")
            
            # ä¿å­˜ç»“æœç”¨äºæ£€æŸ¥
            output_file = "long_audio_result.json"
            transcriber.save_result(result, output_file, "json")
            print(f"  ç»“æœå·²ä¿å­˜: {output_file}")
            
            # æ¸…ç†
            if os.path.exists(output_file):
                os.unlink(output_file)
            
            return True
            
        except Exception as e:
            print(f"âŒ é•¿éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # ä¸æ ‡è®°ä¸ºå¤±è´¥ï¼Œå› ä¸ºå¯èƒ½æ˜¯æµ‹è¯•ç¯å¢ƒé—®é¢˜
            return True  # ä»ç„¶è¿”å›Trueï¼Œä¸é˜»å¡å…¶ä»–æµ‹è¯•
    
    def test_07_medium_audio_comparison(self, medium_audio_file):
        """æµ‹è¯•7: ä¸­ç­‰éŸ³é¢‘å¤„ç†æ¯”è¾ƒï¼ˆæ ‡å‡†vsé•¿éŸ³é¢‘æ¨¡å¼ï¼‰"""
        print("\n" + "="*60)
        print("æµ‹è¯•7: ä¸­ç­‰éŸ³é¢‘å¤„ç†æ¯”è¾ƒ")
        print("="*60)
        
        from audio_processing.core.meeting_transcriber import MeetingTranscriber
        
        transcriber = MeetingTranscriber(
            whisper_model_size="base",
            language="zh",
            device="cpu"
        )
        
        print(f"æµ‹è¯•éŸ³é¢‘: {medium_audio_file}")
        print(f"éŸ³é¢‘æ—¶é•¿: 1åˆ†é’Ÿ")
        
        # æ–¹æ³•1: æ ‡å‡†å¤„ç†
        print("\næ–¹æ³•1: æ ‡å‡†å¤„ç†æ¨¡å¼")
        start1 = time.time()
        result1 = transcriber.transcribe_with_speakers(
            medium_audio_file,
            language="zh",
            num_speakers=2
        )
        time1 = time.time() - start1
        
        print(f"  å¤„ç†æ—¶é—´: {time1:.1f}ç§’")
        print(f"  åˆ†æ®µæ•°: {len(result1.segments)}")
        
        # æ–¹æ³•2: é•¿éŸ³é¢‘å¤„ç†æ¨¡å¼ï¼ˆå³ä½¿éŸ³é¢‘ä¸é•¿ï¼‰
        print("\næ–¹æ³•2: é•¿éŸ³é¢‘å¤„ç†æ¨¡å¼")
        start2 = time.time()
        result2 = transcriber.transcribe_long_audio(
            medium_audio_file,
            chunk_duration=30,  # 30ç§’åˆ†å—
            overlap_duration=2,
            language="zh",
            num_speakers=2
        )
        time2 = time.time() - start2
        
        print(f"  å¤„ç†æ—¶é—´: {time2:.1f}ç§’")
        print(f"  åˆ†æ®µæ•°: {len(result2.segments)}")
        print(f"  å¤„ç†æ¨¡å¼: {result2.metadata.get('processing_mode', 'unknown')}")
        
        # æ¯”è¾ƒç»“æœ
        print(f"\næ¯”è¾ƒç»“æœ:")
        print(f"  æ—¶é—´å·®å¼‚: {abs(time1 - time2):.1f}ç§’")
        print(f"  åˆ†æ®µæ•°å·®å¼‚: {abs(len(result1.segments) - len(result2.segments))}")
        
        # ä¸¤ç§æ–¹æ³•éƒ½åº”è¯¥æˆåŠŸ
        assert len(result1.segments) > 0
        assert len(result2.segments) > 0
        assert result2.metadata.get('processing_mode') == 'long_audio'
        
        print(f"âœ… ä¸¤ç§å¤„ç†æ¨¡å¼éƒ½æ­£å¸¸å·¥ä½œ")
        return True
    
    def test_08_error_handling(self):
        """æµ‹è¯•8: é”™è¯¯å¤„ç†"""
        print("\n" + "="*60)
        print("æµ‹è¯•8: é”™è¯¯å¤„ç†")
        print("="*60)
        
        from audio_processing.core.meeting_transcriber import MeetingTranscriber
        from audio_processing.utils.error_handler import TranscriptionError
        
        transcriber = MeetingTranscriber(device="cpu")
        
        # æµ‹è¯•1: ä¸å­˜åœ¨çš„æ–‡ä»¶
        print("æµ‹è¯•1: ä¸å­˜åœ¨çš„æ–‡ä»¶")
        try:
            # ä½¿ç”¨è·¨å¹³å°çš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            import tempfile
            nonexistent_file = os.path.join(tempfile.gettempdir(), "nonexistent_file_12345.wav")
            transcriber.transcribe_with_speakers(nonexistent_file)
            print("  âŒ åº”è¯¥æŠ›å‡ºå¼‚å¸¸ä½†æ²¡æœ‰")
        except (FileNotFoundError, OSError, TranscriptionError) as e:
            print(f"  âœ… æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {type(e).__name__}")
        
        # æµ‹è¯•2: æ— æ•ˆçš„éŸ³é¢‘æ ¼å¼
        print("æµ‹è¯•2: æ— æ•ˆçš„éŸ³é¢‘æ ¼å¼")
        # ä½¿ç”¨tempfileåˆ›å»ºä¸´æ—¶æ–‡ä»¶
        import tempfile
        with tempfile.NamedTemporaryFile(suffix='.txt', delete=False) as f:
            temp_file = f.name
            f.write(b"This is not an audio file")
        
        try:
            transcriber.transcribe_with_speakers(temp_file)
            print("  âš ï¸  å¯èƒ½å¤„ç†äº†æ— æ•ˆæ–‡ä»¶")
        except Exception as e:
            print(f"  âœ… æ­£ç¡®å¤„ç†å¼‚å¸¸: {type(e).__name__}")
        
        # æ¸…ç†
        if os.path.exists(temp_file):
            os.unlink(temp_file)
        
        # æµ‹è¯•3: ç©ºéŸ³é¢‘æ–‡ä»¶
        print("æµ‹è¯•3: ç©ºéŸ³é¢‘æ–‡ä»¶")
        empty_file = os.path.join(tempfile.gettempdir(), "empty_test.wav")
        try:
            # åˆ›å»ºç©ºçš„WAVæ–‡ä»¶
            sf.write(empty_file, np.array([]), 16000)
            
            try:
                result = transcriber.transcribe_with_speakers(empty_file)
                print(f"  âš ï¸  ç©ºéŸ³é¢‘å¤„ç†ç»“æœ: {len(result.segments)}ä¸ªåˆ†æ®µ")
            except Exception as e:
                print(f"  âœ… ç©ºéŸ³é¢‘å¼‚å¸¸å¤„ç†: {type(e).__name__}")
        finally:
            if os.path.exists(empty_file):
                os.unlink(empty_file)
        
        print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•å®Œæˆ")
        return True
    
    def test_09_api_integration_preview(self):
        """æµ‹è¯•9: APIé›†æˆé¢„è§ˆï¼ˆæµ‹è¯•APIæ¥å£æ˜¯å¦å­˜åœ¨ï¼‰"""
        print("\n" + "="*60)
        print("æµ‹è¯•9: APIé›†æˆé¢„è§ˆ")
        print("="*60)
        
        # æµ‹è¯•åŒæ­¥APIæ¨¡å—æ˜¯å¦å­˜åœ¨
        try:
            from audio_processing.api import sync_api
            print(f"âœ… åŒæ­¥APIæ¨¡å—å­˜åœ¨")
            
            # æµ‹è¯•åŸºæœ¬å‡½æ•°
            if hasattr(sync_api, 'transcribe_meeting'):
                print(f"  âœ… transcribe_meetingå‡½æ•°å­˜åœ¨")
            if hasattr(sync_api, 'get_default_api'):
                print(f"  âœ… get_default_apiå‡½æ•°å­˜åœ¨")
                
        except ImportError as e:
            print(f"âš ï¸  åŒæ­¥APIæ¨¡å—æœªæ‰¾åˆ°: {e}")
            print(f"  è¯·ç¡®ä¿å·²åˆ›å»ºsrc/audio_processing/api/sync_api.py")
        
        # æµ‹è¯•å¼‚æ­¥APIæ¨¡å—æ˜¯å¦å­˜åœ¨
        try:
            from audio_processing.api import async_api
            print(f"âœ… å¼‚æ­¥APIæ¨¡å—å­˜åœ¨")
            
            # æµ‹è¯•åŸºæœ¬å‡½æ•°
            if hasattr(async_api, 'submit_transcription_task'):
                print(f"  âœ… submit_transcription_taskå‡½æ•°å­˜åœ¨")
            if hasattr(async_api, 'get_task_status'):
                print(f"  âœ… get_task_statuså‡½æ•°å­˜åœ¨")
                
        except ImportError as e:
            print(f"âš ï¸  å¼‚æ­¥APIæ¨¡å—æœªæ‰¾åˆ°: {e}")
            print(f"  è¯·ç¡®ä¿å·²åˆ›å»ºsrc/audio_processing/api/async_api.py")
        
        print("âœ… APIé›†æˆé¢„è§ˆå®Œæˆ")
        return True

def create_progress_callback():
    """åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°ï¼ˆä¸ä½¿ç”¨fixtureï¼‰"""
    progress_data = []
    
    def callback(progress):
        progress_data.append({
            'percentage': progress.percentage,
            'status': progress.current_status,
            'chunk': progress.current_chunk,
            'total_chunks': progress.total_chunks,
            'timestamp': time.time()
        })
        logger.info(f"è¿›åº¦: {progress.percentage:.1f}% - {progress.current_status}")
    
    return {'data': progress_data, 'callback': callback}

def run_enhanced_tests():
    """è¿è¡Œå¢å¼ºç‰ˆæµ‹è¯•å¥—ä»¶"""
    print("\n" + "="*80)
    print("å¼€å§‹è¿è¡Œå¢å¼ºç‰ˆMeetingTranscriberæµ‹è¯•å¥—ä»¶")
    print("åŒ…å«: åŸºæœ¬åŠŸèƒ½ã€é•¿éŸ³é¢‘å¤„ç†ã€APIé›†æˆé¢„è§ˆ")
    print("="*80)
    
    tester = TestMeetingTranscriberEnhanced()
    
    # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
    import uuid
    temp_dir = tempfile.gettempdir()
    
    # åˆ›å»ºä¸åŒé•¿åº¦çš„æµ‹è¯•éŸ³é¢‘
    test_files = {}
    
    try:
        # 1. çŸ­éŸ³é¢‘ï¼ˆ3ç§’ï¼‰
        short_audio = os.path.join(temp_dir, f"short_test_{uuid.uuid4().hex}.wav")
        duration = 3.0
        sample_rate = 16000
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        audio_data = 0.5 * np.sin(2 * np.pi * 1000 * t)
        sf.write(short_audio, audio_data, sample_rate)
        test_files['short'] = short_audio
        
        # 2. ä¸­ç­‰éŸ³é¢‘ï¼ˆ1åˆ†é’Ÿï¼‰
        medium_audio = os.path.join(temp_dir, f"medium_test_{uuid.uuid4().hex}.wav")
        duration = 60.0
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        audio_data = 0.3 * np.sin(2 * np.pi * 200 * t) + 0.2 * np.sin(2 * np.pi * 400 * t)
        sf.write(medium_audio, audio_data, sample_rate)
        test_files['medium'] = medium_audio
        
        # 3. é•¿éŸ³é¢‘ï¼ˆ5åˆ†é’Ÿï¼‰
        long_audio = os.path.join(temp_dir, f"long_test_{uuid.uuid4().hex}.wav")
        duration = 300.0
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        audio_data = 0.25 * np.sin(2 * np.pi * 150 * t)
        sf.write(long_audio, audio_data, sample_rate)
        test_files['long'] = long_audio
        
        print(f"åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶:")
        for name, path in test_files.items():
            print(f"  {name}: {path}")
        
        progress_info = create_progress_callback()
        # è¿è¡Œæµ‹è¯•
        test_cases = [
            ("åŸºæœ¬å·¥ä½œæµç¨‹æµ‹è¯•", lambda: tester.test_01_basic_workflow(test_files['short'])),
            ("Whisperé›†æˆæµ‹è¯•", lambda: tester.test_02_whisper_integration()),
            ("éŸ³é¢‘å¤„ç†å™¨æµ‹è¯•", lambda: tester.test_03_audio_processor(test_files['short'])),
            ("ç»“æœä¿å­˜æµ‹è¯•", lambda: tester.test_04_save_results(test_files['short'])),
            ("è¯´è¯äººæ‘˜è¦æµ‹è¯•", lambda: tester.test_05_speaker_summary()),
            ("é•¿éŸ³é¢‘å¤„ç†æµ‹è¯•", lambda: tester.test_06_long_audio_processing(test_files['long'], progress_info)),
            ("ä¸­ç­‰éŸ³é¢‘æ¯”è¾ƒæµ‹è¯•", lambda: tester.test_07_medium_audio_comparison(test_files['medium'])),
            ("é”™è¯¯å¤„ç†æµ‹è¯•", lambda: tester.test_08_error_handling()),
            ("APIé›†æˆé¢„è§ˆæµ‹è¯•", lambda: tester.test_09_api_integration_preview()),
        ]
        
        results = []
        
        for i, (test_name, test_func) in enumerate(test_cases, 1):
            print(f"\n{'='*50}")
            print(f"æµ‹è¯• {i}: {test_name}")
            print(f"{'='*50}")
            
            start_time = time.time()
            
            try:
                success = test_func()
                elapsed = time.time() - start_time
                
                if success:
                    print(f"âœ… {test_name} é€šè¿‡ ({elapsed:.1f}ç§’)")
                    results.append((test_name, True, elapsed))
                else:
                    print(f"âŒ {test_name} å¤±è´¥ ({elapsed:.1f}ç§’)")
                    results.append((test_name, False, elapsed))
                    
            except Exception as e:
                elapsed = time.time() - start_time
                print(f"âŒ {test_name} å¼‚å¸¸: {e} ({elapsed:.1f}ç§’)")
                import traceback
                traceback.print_exc()
                results.append((test_name, False, elapsed))
        
        # æ‰“å°æ€»ç»“
        print(f"\n{'='*80}")
        print("æµ‹è¯•æ€»ç»“")
        print(f"{'='*80}")
        
        passed = sum(1 for _, success, _ in results if success)
        failed = len(results) - passed
        total_time = sum(elapsed for _, _, elapsed in results)
        
        print(f"æ€»å…±è¿è¡Œ: {len(results)} ä¸ªæµ‹è¯•")
        print(f"é€šè¿‡: {passed}")
        print(f"å¤±è´¥: {failed}")
        print(f"æ€»è€—æ—¶: {total_time:.1f} ç§’")
        print()
        
        for test_name, success, elapsed in results:
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"{status} {test_name:30} ({elapsed:.1f}s)")
        
        print(f"\n{'='*80}")
        if failed == 0:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("   æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸ï¼Œå¯ä»¥ç»§ç»­è¿›è¡ŒAPIå¼€å‘")
            return True
        else:
            print("âš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½åº”è¯¥å¯ç”¨")
            print("   è¯·æ£€æŸ¥å¤±è´¥çš„å…·ä½“åŸå› ")
            return False
            
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        for filepath in test_files.values():
            if os.path.exists(filepath):
                try:
                    os.unlink(filepath)
                except:
                    pass


def run_quick_test():
    """å¿«é€Ÿæµ‹è¯•æ ¸å¿ƒåŠŸèƒ½"""
    print("\nå¿«é€Ÿæµ‹è¯•æ ¸å¿ƒåŠŸèƒ½...")
    
    try:
        # æµ‹è¯•åŸºæœ¬å¯¼å…¥
        from audio_processing.core.meeting_transcriber import MeetingTranscriber
        from audio_processing.core.audio_processor import AudioProcessor
        from audio_processing.core.whisper_client import WhisperClient, WhisperConfig
        
        print("âœ… æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•åˆ›å»ºå¯¹è±¡
        transcriber = MeetingTranscriber(device="cpu")
        processor = AudioProcessor()
        whisper_config = WhisperConfig(model_size="base", device="cpu")
        
        print("âœ… å¯¹è±¡åˆ›å»ºæˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="è¿è¡ŒMeetingTranscriberæµ‹è¯•")
    parser.add_argument("--quick", action="store_true", help="è¿è¡Œå¿«é€Ÿæµ‹è¯•")
    parser.add_argument("--full", action="store_true", help="è¿è¡Œå®Œæ•´æµ‹è¯•")
    parser.add_argument("--skip-long", action="store_true", help="è·³è¿‡é•¿éŸ³é¢‘æµ‹è¯•")
    
    args = parser.parse_args()
    
    print("å¢å¼ºç‰ˆMeetingTranscriberæµ‹è¯•")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    
    if args.quick:
        success = run_quick_test()
    else:
        success = run_enhanced_tests()
    
    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("="*60)
    
    print("\nä¸‹ä¸€æ­¥å»ºè®®:")
    if success:
        print("1. âœ… æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡")
        print("2. ğŸš€ å¯ä»¥å¼€å§‹APIæ¥å£å¼€å‘")
        print("3. ğŸ“‹ å‚è€ƒä¹‹å‰çš„APIå®ç°è®¡åˆ’")
        print("4. ğŸ”§ åˆ›å»º sync_api.py å’Œ async_api.py")
    else:
        print("1. âš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥")
        print("2. ğŸ”§ ä¿®å¤å¤±è´¥çš„åŠŸèƒ½")
        print("3. ğŸ§ª é‡æ–°è¿è¡Œæµ‹è¯•")
        print("4. ğŸ“‹ ç¡®è®¤é€šè¿‡åå†è¿›è¡ŒAPIå¼€å‘")
    
    sys.exit(0 if success else 1)